<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>redis-cell 限流模块</title>
      <link href="/2019/09/04/redis-cell-%E9%99%90%E6%B5%81%E6%A8%A1%E5%9D%97/"/>
      <url>/2019/09/04/redis-cell-%E9%99%90%E6%B5%81%E6%A8%A1%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>redis 4.0 以后开始支持扩展模块，redis-cell 是一个用rust语言编写的基于<strong>令牌桶算法</strong>的的限流模块，提供<strong>原子性的限流功能</strong>，并允许突发流量，可以<strong>很方便的应用于分布式环境中</strong>。</p><h3 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h3><p>令牌桶算法的原理是定义一个按一定速率产生token的桶，每次去桶中申请token，若桶中没有足够的token则申请失败，否则成功。在请求不多的情况下，桶中的token基本会饱和，此时若流量激增，并不会马上拒绝请求，所以这种算法允许一定的流量激增。<br>定义一个令牌桶，其拥有几个关键属性</p><ol><li>桶容量</li><li>令牌产生速率</li><li>当前桶中令牌数</li><li>最近一次取（生成）令牌时间<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2>该模块只提供了一个命令：CL.THROTTLE<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CL.THROTTLE user123 15 30 60 1</span><br><span class="line">               ▲     ▲  ▲  ▲ ▲</span><br><span class="line">               |     |  |  | └───── apply 1 token (default if omitted)（每次申请的令牌数）</span><br><span class="line">               |     |  └──┴─────── 30 tokens / 60 seconds（往桶中的漏水速率）</span><br><span class="line">               |     └───────────── 15 max_burst （桶容量）</span><br><span class="line">               └─────────────────── key &quot;user123&quot;</span><br></pre></td></tr></table></figure></li></ol><p>执行结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CL.THROTTLE user123 15 30 60</span><br><span class="line">1) (integer) 0</span><br><span class="line">2) (integer) 16</span><br><span class="line">3) (integer) 15</span><br><span class="line">4) (integer) -1</span><br><span class="line">5) (integer) 2</span><br></pre></td></tr></table></figure><p>每个数组项的含义是：</p><ol><li>行动是否有限：<br>0 表示允许该操作。<br>1 表示操作受限/阻止。</li><li>密钥的容量（max_burst+ 1）。这相当于常见的X-RateLimit-LimitHTTP标头。</li><li>密钥的剩余限制。相当于X-RateLimit-Remaining。</li><li>如果被拒绝了用户需要多长时间重试，-1是允许的操作。相当于Retry-After。</li><li>多长时间漏斗完全空出来的秒数。相当于X-RateLimit-Reset。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HyperLogLog</title>
      <link href="/2019/09/03/HyperLogLog/"/>
      <url>/2019/09/03/HyperLogLog/</url>
      
        <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>HyperLogLog是redis的高级数据结构，提供不精确的去重功能，标准误差0.81%</p><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>一个页面有几千万访问量，统计这个页面一天的UV（UV需要去重，同一用户一天的多次请求只能算一次），比如105万的访问量与106万的访问量并没有多大区别，所以可以用HyperLogLog实现。</p><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><ol><li>pfadd<br>用法 ：pfadd key value…</li><li>pfcount<br>用法 ：pfcount key</li><li>pfmerge<br>用法 ：用于将多个pf计数值累加在一起形成一个新的pf值， pf为发明HyperLogLog的人名字首字母缩写。<br><img src="/images/2019/09/03/88db4dd0-ce50-11e9-aefc-35a1bfce56cf.png" alt="pfmerge.png"><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2>HyperLogLog需要12KB存储空间，不适合单个用户使用，如果有上亿用户，相比于set的方案，存储空间只能算九牛一毛了。<br>当计数较小的时候。Redis对HyperLogLog有优化，计数小的时候空间占用很小。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> HyperLogLog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode刷题记录</title>
      <link href="/2019/08/28/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
      <url>/2019/08/28/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>我的leetcode GitHub地址：<a href="https://github.com/easonsynnex/leetcode" target="_blank" rel="noopener">leetcode记录</a><br>先从数组-简单开始，已完成如下<br>2019-08-27：<a href="https://github.com/easonsynnex/leetcode/tree/master/src/main/java/com/eason/leetcode/leetcode0001" target="_blank" rel="noopener">1.两数之和</a>，<a href="https://github.com/easonsynnex/leetcode/tree/master/src/main/java/com/eason/leetcode/leetcode0026" target="_blank" rel="noopener">26.删除排序数组中的重复项</a><br>2019-08-28：<a href="https://github.com/easonsynnex/leetcode/tree/master/src/main/java/com/eason/leetcode/leetcode0027" target="_blank" rel="noopener">27.移除元素</a>，<a href="https://github.com/easonsynnex/leetcode/tree/master/src/main/java/com/eason/leetcode/leetcode0035" target="_blank" rel="noopener">35.搜索插入位置</a><br>2019-08-28：<a href="https://github.com/easonsynnex/leetcode/tree/master/src/main/java/com/eason/leetcode/leetcode0066" target="_blank" rel="noopener">66.加一</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis实现消息队列的方案</title>
      <link href="/2019/08/25/Redis%E5%AE%9E%E7%8E%B0%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%96%B9%E6%A1%88/"/>
      <url>/2019/08/25/Redis%E5%AE%9E%E7%8E%B0%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<p>Redis作为内存中的数据结构存储，常用作数据库、缓存和消息代理。它支持数据结构，如 字符串，散列，列表，集合，带有范围查询的排序集（sorted sets），位图（bitmaps），超级日志（hyperloglogs），具有半径查询和流的地理空间索引。Redis具有内置复制，Lua脚本，LRU驱逐，事务和不同级别的磁盘持久性，并通过Redis Sentinel和Redis Cluster自动分区。<br>  为了实现其出色的性能，Redis使用<strong>内存数据集（in-memory dataset）</strong>。<br>MQ应用有很多，比如ActiveMQ,RabbitMQ,Kafka等，但是也可以基于redis来实现，可以降低系统的维护成本和实现复杂度，本篇介绍redis中实现消息队列的几种方案。<br>    1. 基于List的 LPUSH+BRPOP 的实现<br>    2. PUB/SUB，订阅/发布模式<br>    3. 基于Sorted-Set的实现<br>    4. 基于Stream类型的实现</p><h2 id="基于异步消息队列List-lpush-brpop-rpush-blpop"><a href="#基于异步消息队列List-lpush-brpop-rpush-blpop" class="headerlink" title="基于异步消息队列List lpush-brpop(rpush-blpop)"></a>基于异步消息队列List lpush-brpop(rpush-blpop)</h2><p>  使用<strong>rpush</strong>和<strong>lpush</strong>操作入队列，<strong>lpop</strong>和<strong>rpop</strong>操作出队列。<br>  <strong>List支持多个生产者和消费者并发进出消息</strong>，每个消费者拿到都是<strong>不同</strong>的列表元素。<br>  但是当队列为空时，lpop和rpop会一直空轮训，消耗资源；所以引入阻塞读blpop和brpop（b代表blocking），阻塞读在队列没有数据的时候进入休眠状态，<br>  一旦数据到来则立刻醒过来，消息延迟几乎为零。<br>  <strong>注意</strong><br>  你以为上面的方案很完美？还有个问题需要解决：空闲连接的问题。<br>  如果线程一直阻塞在那里，Redis客户端的连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用，这个时候blpop和brpop或抛出异常，<br>  所以在编写客户端消费者的时候要小心，如果捕获到异常，还有重试。<br>  <strong>缺点：</strong></p><ul><li><p>做消费者确认ACK麻烦，不能保证消费者消费消息后是否成功处理的问题（宕机或处理异常等），通常需要维护一个Pending列表，保证消息处理确认。</p></li><li><p>不能做广播模式，如pub/sub，消息发布/订阅模型</p></li><li><p>不能重复消费，一旦消费就会被删除</p></li><li><p>不支持分组消费</p><h2 id="PUB-SUB-订阅-发布模式"><a href="#PUB-SUB-订阅-发布模式" class="headerlink" title="PUB/SUB,订阅/发布模式"></a>PUB/SUB,订阅/发布模式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SUBSCRIBE，用于订阅信道</span><br><span class="line">PUBLISH，向信道发送消息</span><br><span class="line">UNSUBSCRIBE，取消订阅</span><br></pre></td></tr></table></figure><p>此模式允许生产者只生产一次消息，由中间件负责将消息复制到多个消息队列，每个消息队列由对应的消费组消费。</p></li></ul><p>  <strong>优点</strong></p><ul><li>典型的广播模式，一个消息可以发布到多个消费者</li><li>多信道订阅，消费者可以同时订阅多个信道，从而接收多类消息</li><li>消息即时发送，消息不用等待消费者读取，消费者会自动接收到信道发布的消息</li></ul><p>  <strong>缺点</strong></p><ul><li>消息一旦发布，不能接收。换句话就是发布时若客户端不在线，则消息丢失，不能寻回</li><li>不能保证每个消费者接收的时间是一致的</li><li>若消费者客户端出现消息积压，到一定程度，会被强制断开，导致消息意外丢失。通常发生在消息的生产远大于消费速度时<br><strong><em>可见，Pub/Sub 模式不适合做消息存储，消息积压类的业务，而是擅长处理广播，即时通讯，即时反馈的业务。</em></strong><h2 id="基于Sorted-Set的实现"><a href="#基于Sorted-Set的实现" class="headerlink" title="基于Sorted-Set的实现"></a>基于Sorted-Set的实现</h2>Sortes Set(有序列表)，类似于java的SortedSet和HashMap的结合体，一方面她是一个set，保证内部value的唯一性，另一方面它可以给每个value赋予一个score，代表这个value的<br>排序权重。内部实现是“跳跃表”。<br>有序集合的方案是在自己确定消息顺ID时比较常用，使用集合成员的Score来作为消息ID，保证顺序，还可以保证消息ID的单调递增。通常可以使用时间戳+序号的方案。确保了消息ID的单调递增，利用SortedSet的依据<br>Score排序的特征，就可以制作一个有序的消息队列了。</li></ul><p>  <strong>优点</strong><br>  就是可以自定义消息ID，在消息ID有意义时，比较重要。<br>  <strong>缺点</strong><br>  缺点也明显，不允许重复消息（因为是集合），同时消息ID确定有错误会导致消息的顺序出错。</p><h2 id="基于Stream类型的实现"><a href="#基于Stream类型的实现" class="headerlink" title="基于Stream类型的实现"></a>基于Stream类型的实现</h2><p>  Stream为redis 5.0后新增的数据结构。支持多播的可持久化消息队列，实现借鉴了Kafka设计。<br>  <img src="/images/2019/08/25/fc70de40-c72a-11e9-b114-619b79bcbc54.jpg" alt="stream.jpg"><br>  Redis Stream的结构如上图所示，<strong>它有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的ID和对应的内容</strong>。<strong>消息是持久化的</strong>，Redis重启后，内容还在。</p><p>每个Stream都有唯一的名称，它就是Redis的key，在我们<strong>首次使用xadd指令追加消息时自动创建</strong>。</p><p><strong>每个Stream都可以挂多个消费组，每个消费组会有个游标last_delivered_id在Stream数组之上往前移动，表示当前消费组已经消费到哪条消息了</strong>。每个消费组都有一个Stream内唯一的名称，消费组不会自动创建，它需要单独的指令xgroup create进行创建，需要指定从Stream的某个消息ID开始消费，这个ID用来初始化last_delivered_id变量。</p><p>每个消费组(Consumer Group)的状态都是独立的，相互不受影响。也就是说<strong>同一份Stream内部的消息会被每个消费组都消费到</strong>。</p><p><strong>同一个消费组(Consumer Group)可以挂接多个消费者(Consumer)，这些消费者之间是竞争关系</strong>，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者者有一个组内唯一名称。</p><p>消费者(Consumer)内部会有个状态变量<strong>pending_ids</strong>，它记录了当前已经被客户端读取的消息，但是还没有ack。如果客户端没有ack，这个变量里面的消息ID会越来越多，一旦某个消息被ack，它就开始减少。这个pending_ids变量在Redis官方被称之为PEL，也就是Pending Entries List，这是一个很核心的数据结构，它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。<br>  <strong>增删改查</strong></p><ol><li>xadd <strong>追加消息</strong></li><li>xdel 删除消息，这里的删除仅仅是设置了标志位，不影响消息总长度 </li><li>xrange <strong>获取消息列表</strong>，会自动过滤已经删除的消息</li><li>xlen 消息长度 </li><li>del 删除Stream<h3 id="独立消费"><a href="#独立消费" class="headerlink" title="独立消费"></a>独立消费</h3>我们可以在不定义消费组的情况下进行Stream消息的独立消费，当Stream没有新消息时，甚至可以阻塞等待。Redis设计了一个单独的消费指令xread，可以将Stream当成普通的消息队列(list)来使用。使用xread时，我们可以完全忽略消费组(Consumer Group)的存在，就好比Stream就是一个普通的列表(list)。<h3 id="创建消费组"><a href="#创建消费组" class="headerlink" title="创建消费组"></a>创建消费组</h3>Stream通过xgroup create指令创建消费组(Consumer Group)，需要传递起始消息ID参数用来初始化last_delivered_id变量。<h3 id="消费"><a href="#消费" class="headerlink" title="消费"></a>消费</h3>Stream提供了xreadgroup指令可以进行消费组的组内消费，需要提供消费组名称、消费者名称和起始消息ID。它同xread一样，也可以阻塞等待新消息。读到新消息后，对应的消息ID就会进入消费者的PEL(正在处理的消息)结构里，客户端处理完毕后使用xack指令通知服务器，本条消息已经处理完毕，该消息ID就会从PEL中移除。<h3 id="Stream消息太多怎么办"><a href="#Stream消息太多怎么办" class="headerlink" title="Stream消息太多怎么办"></a>Stream消息太多怎么办</h3>读者很容易想到，要是消息积累太多，Stream的链表岂不是很长，内容会不会爆掉就是个问题了。xdel指令又不会删除消息，它只是给消息做了个标志位。<br>Redis自然考虑到了这一点，所以它提供了一个定长Stream功能。在xadd的指令提供一个定长长度maxlen，就可以将老的消息干掉，确保最多不超过指定长度。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; xlen codehole</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; xadd codehole maxlen 3 * name xiaorui age 1</span><br><span class="line">1527855160273-0</span><br><span class="line">127.0.0.1:6379&gt; xlen codehole</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure></li></ol><p>我们看到Stream的长度被砍掉了。</p><h4 id="消息如果忘记ACK会怎样"><a href="#消息如果忘记ACK会怎样" class="headerlink" title="消息如果忘记ACK会怎样"></a>消息如果忘记ACK会怎样</h4><p><img src="/images/2019/08/25/f2378a60-c72e-11e9-b114-619b79bcbc54.jpg" alt="PEL.jpg"><br>Stream在每个消费者结构中保存了正在处理中的消息ID列表PEL，如果消费者收到了消息处理完了但是没有回复ack，就会导致PEL列表不断增长，如果有很多消费组的话，那么这个PEL占用的内存就会放大。</p><h3 id="PEL如何避免消息丢失"><a href="#PEL如何避免消息丢失" class="headerlink" title="PEL如何避免消息丢失"></a>PEL如何避免消息丢失</h3><p>在客户端消费者读取Stream消息时，Redis服务器将消息回复给客户端的过程中，客户端突然断开了连接，消息就丢失了。但是PEL里已经保存了发出去的消息ID。待客户端重新连上之后，可以再次收到PEL中的消息ID列表。不过此时xreadgroup的起始消息必须是任意有效的消息ID，一般将参数设为0-0，表示读取所有的PEL消息以及自last_delivered_id之后的新消息。</p><h3 id="分区Partition"><a href="#分区Partition" class="headerlink" title="分区Partition"></a>分区Partition</h3><p>Redis没有原生支持分区的能力，想要使用分区，需要分配多个Stream，然后在客户端使用一定的策略来讲消息放入不同的stream。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>Stream的消费模型借鉴了kafka的消费分组的概念，它弥补了Redis Pub/Sub不能持久化消息的缺陷。但是它又不同于kafka，kafka的消息可以分partition，而Stream不行。如果非要分parition的话，得在客户端做，提供不同的Stream名称，对消息进行hash取模来选择往哪个Stream里塞。如果读者稍微研究过Redis作者的另一个开源项目Disque的话，这极可能是作者意识到Disque项目的活跃程度不够，所以将Disque的内容移植到了Redis里面。这只是本人的猜测，未必是作者的初衷。如果读者有什么不同的想法，可以在评论区一起参与讨论。</p><p>参考文章：<br>    <a href="https://blog.csdn.net/enmotech/article/details/81230531" target="_blank" rel="noopener">https://blog.csdn.net/enmotech/article/details/81230531</a><br>    <a href="http://www.hellokang.net/redis/message-queue-by-redis.html" target="_blank" rel="noopener">http://www.hellokang.net/redis/message-queue-by-redis.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录hexo博客搭建的一些过程</title>
      <link href="/2019/08/24/%E8%AE%B0%E5%BD%95hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%9A%84%E4%B8%80%E4%BA%9B%E8%BF%87%E7%A8%8B/"/>
      <url>/2019/08/24/%E8%AE%B0%E5%BD%95hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%9A%84%E4%B8%80%E4%BA%9B%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>很早就想自己写博客了，从去年开始在幕布上开始记笔记，但是用其他网站的资源总是有很多限制，所以自己用Hexo搭建博客，希望自己能够坚持记录，下面简要记录一下搭建博客过程中的一些要点，便于以后能够更好地整理。</p><h1 id="一、自己服务器搭建"><a href="#一、自己服务器搭建" class="headerlink" title="一、自己服务器搭建"></a>一、自己服务器搭建</h1><h2 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h2><p>  按照官网提供的方式安装,安装目录为<strong>/softwares/blog</strong><br>  启动命令为hexo s(start),官方说用$ hexo s &amp;，但是不稳定，用pm2来接管hexo进程，具体方式如下：</p><ol><li><p>安装pm2<br>npm  install -g pm2</p></li><li><p>写一个执行脚本hexo_run.js</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">const &#123; exec &#125; = require(&apos;child_process&apos;)</span><br><span class="line">exec(&apos;hexo server&apos;,(error, stdout, stderr) =&gt; &#123;</span><br><span class="line">        if(error)&#123;</span><br><span class="line">                console.log(&apos;exec error: $&#123;error&#125;&apos;)</span><br><span class="line">                return</span><br><span class="line">        &#125;</span><br><span class="line">        console.log(&apos;stdout: $&#123;stdout&#125;&apos;);</span><br><span class="line">        console.log(&apos;stderr: $&#123;stderr&#125;&apos;);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>3.运行脚本<br>pm2 start hexo_run.js<br><strong>pm2一些命令</strong><br>pm2 list<br>pm2 stop id(进程号)<br>pm2 stop all</p><h2 id="Hexo主题安装"><a href="#Hexo主题安装" class="headerlink" title="Hexo主题安装"></a>Hexo主题安装</h2><p>到Hexo官网的主题中选中了一个主题，<br>主题地址：<a href="https://github.com/niemingzhao/niemingzhao.github.io/tree/theme，按照README安装" target="_blank" rel="noopener">https://github.com/niemingzhao/niemingzhao.github.io/tree/theme，按照README安装</a><br>评论使用的是Leancloud，统计使用的百度</p><h2 id="Nginx代理"><a href="#Nginx代理" class="headerlink" title="Nginx代理"></a>Nginx代理</h2><p>使用Nginx代理<br>1.进入nginx安装目录下的sbin目录下<br>cd /usr/local/nginx/sbin/<br>2.启动<br>./nginx -c /usr/local/nginx/conf/nginx.conf<br>3.reload<br>./nginx -s reload<br>4.stop<br>./nginx -s stop<br>5.怎么修改nginx配置文件nginx.conf<br>修改目录/usr/local/nginx/conf/nginx.conf</p><h1 id="二、搭建到Github"><a href="#二、搭建到Github" class="headerlink" title="二、搭建到Github"></a>二、搭建到Github</h1><p>如果搭建到自己的服务器上，需要有自己的服务器，所以想放到Github上去。</p><ol><li>本地搭建好hexo</li><li>修改hexo 配置文件，修改git deploy配置信息</li><li>新建仓库，名为yourname.github.io,同时在本地hexosource目录下新建CNAME文件，内容为(<a href="http://www.cdeason.cn)，用于github允许其他我的域名访问github">www.cdeason.cn)，用于github允许其他我的域名访问github</a> pages。</li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> 记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
